{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 启动训练\n",
    "\n",
    "```bash\n",
    "python final_src/main.py train --model-path-base model_cv --epochs 30 --batch_size 64 --N_neuron 128 --N_neuron2 128 --N_trans 1 --N_lstm 2 --N_head 2 \n",
    "```\n",
    "\n",
    "\n",
    "__参数解释__\n",
    "\n",
    "N_neuron: 第一次卷积输出维度\n",
    "\n",
    "N_neuron2: N_neuron2 * 2为双向lstm输出维度\n",
    "\n",
    "N_trans: transformer层数量\n",
    "\n",
    "N_lstm: lstm层数量\n",
    "\n",
    "N_head: MultiheadAttention head数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 预测\n",
    "```bash\n",
    "python final_src/main.py --model-path-bash model_cv/[path] --N_neuron 128 --N_neuron2 128 --N_trans 1 --N_lstm 2 --N_head 2 \n",
    "```\n",
    "\n",
    "之后用交叉验证的20个模型分别预测并求平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n"
     ]
    }
   ],
   "source": [
    "%cd work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admit.py        \u001b[0m\u001b[01;34mfinal_src2\u001b[0m/  out.txt            \u001b[01;34msrc2\u001b[0m/        test_log.txt\r\n",
      "\u001b[01;34mdata\u001b[0m/           \u001b[01;34mmodel\u001b[0m/       README.txt         src2.zip     \u001b[01;34mtrain_log\u001b[0m/\r\n",
      "dmodel_grid.py  \u001b[01;34mmodel-0\u001b[0m/     rnabaidu(1).ipynb  \u001b[01;34msrc_bert\u001b[0m/    train_log.txt\r\n",
      "emb_out.txt     \u001b[01;34mmodel_cv\u001b[0m/    rnabaidu.ipynb     \u001b[01;34msrc_resnet\u001b[0m/\r\n",
      "\u001b[01;34mfinal_src\u001b[0m/      \u001b[01;34mmodelDL\u001b[0m/     \u001b[01;34msrc\u001b[0m/               \u001b[01;34mtest_log\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "2021-05-13 19:37:10.955196\n",
      "# python3 final_src/main.py train --model-path-base model_cv --epochs 30\n",
      "# Training set contains 4750 Sequences.\n",
      "# Validation set contains 250 Sequences.\n",
      "# Paddle: Using device: CUDAPlace(0)\n",
      "# Initializing model...\n",
      "initializing vacabularies... done.\n",
      "Sequence(6): ['<START>', '<STOP>', 'A', 'C', 'G', 'U']\n",
      "Brackets(5): ['<START>', '<STOP>', '(', ')', '.']\n",
      "# Checking validation 1 times an epoch (every 4750 batches)\n",
      "(-1, -1) (-1, -1) (-1, -1)\n",
      "x1reshape: (-1, -1, 1)\n",
      "x1onehot: (-1, -1, 5)\n",
      "concat: (-1, -1, 10)\n",
      "conv1: (-1, -1, 128)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/work/final_src/network.py:36\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /home/aistudio/work/final_src/network.py:42\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "trans: (-1, -1, 128)\n",
      "<class 'paddle.fluid.framework.Variable'>\n",
      "lstm: (-1, -1, 256)\n",
      "lstm2: (-1, -1, 256)\n",
      "concat2: (-1, -1, 257)\n",
      "conv2: (-1, -1, 1)\n",
      "out: (-1, -1)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/data_feeder.py:56: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool, np.float16, np.float32, np.float64, np.int8, np.int16,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: final_src/main.py:158\n",
      "The behavior of expression A - B has been unified with elementwise_sub(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_sub(X, Y, axis=0) instead of A - B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: final_src/main.py:160\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: final_src/main.py:160\n",
      "The behavior of expression A / B has been unified with elementwise_div(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_div(X, Y, axis=0) instead of A / B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "W0513 19:37:14.917979   448 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0513 19:37:14.918042   448 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "!python final_src/main.py train --model-path-base model_cv --epochs 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 赛题理解\n",
    "\n",
    "赛题是根据RNA的一级结构和预测的二级结构来构建模型预测RNA各个碱基的未配对概率。\n",
    "\n",
    "RNA序列由四种碱基组成，分别是腺嘌呤，胞嘧啶，鸟嘌呤和尿嘧啶。这四种碱基组成的序列就是RNA序列，也叫做**RNA的一级结构**。我们把2D平面上由**碱基配对**形成的结构称之为**RNA的二级结构**，并且用点括号表示法——使用点“.”，和成对的括号，即“(”和“)”，组成的序列来表示其二级结构。\n",
    "\n",
    "预测碱基未配对概率，可以理解为：预测RNA序列中各碱基对应位置上的二级结构有多大概率是“.”。预测结果是一个一维的由范围在0~1之间数字组成的序列。\n",
    "\n",
    "可见，这在深度学习中是一种典型的N-N的seq2seq问题。\n",
    "\n",
    "# 思路分享\n",
    "\n",
    "## Word-embedding or One-hot\n",
    "\n",
    "首先需要解决的是输入序列的编码问题。我们想到word-embedding和one-hot方法。我们都进行尝试后发现，使用one-hot方法进行编码时，预测得到的结果要好于word-embedding。\n",
    "\n",
    "在NLP任务中，字词编码的词表非常大，导致维度多且稀疏，所以需要word-embedding得到词语的低维稠密表示。这样做的好处是，不同字词间有很大的联系，而这一联系可以通过词向量间的cos距离等来刻画。而RNA碱基种类少，只有4种，只需要一个4维的one-hot向量就可以表示。而且，不同碱基间的关联度小，差异性才是更重要的特点。Onehot向量可以充分表达差异性，因为不同onehot向量在高维空间中相互垂直。\n",
    "\n",
    "## K-mers with 1D convolutions\n",
    "\n",
    "NLP任务中，有时会用到的一种叫做n-gram的技术，即将多个词绑定为一个整体。这个技术在蛋白质序列、DNA序列以及基因组相关的研究中也常常使用，称为k-mers。参考论文《Nucleic Transformer: Deep Learning on Nucleic Acids with Self-Attention and Convolutions》[1]，我们将一维卷积和k-mers结合起来，通过CNN捕获局部信息，并使其具有生物学意义。使用k-mers构建词表时，假设k=5，那么词表的大小就是4^5=1024。这种处理，相当于在编码时将一定范围内的上下文也考虑了进去，增加了词的多样性，可以一定程度上提高模型的学习能力。\n",
    "\n",
    "经过调试，k-mers长度为9，即使用9-mer时，预测效果最好。\n",
    "\n",
    "## Transformer encoder\n",
    "\n",
    "Transformer中multi-head允许不同的头学习输入的不同的隐藏层表示，可以提高预测性能。此外，self-attention机制允许我们先前构造的每个k-mer都注意到所有的k-mer，很好地解决序列内长距离的依赖问题。\n",
    "\n",
    "## Bi LSTM\n",
    "\n",
    "我们在尝试了仅使用transformer、仅使用Bi LSTM，和同时使用transformer和Bi LSTM。我们发现同时使用transformer和bi LSTM，且bi LSTM层数为3时，预测效果最好。\n",
    "\n",
    "## 20-Fold Cross Validation \n",
    "\n",
    "由于数据集较小，为了确定最适合的超参数，我们使用了20折交叉验证。\n",
    "\n",
    "20折交叉训练后我们相当于得到了20个模型，并分别对测试集做预测，结果分别保存在20个txt文件，我们将它transform成csv格式，再进行单元格拆分-对应位置求平均-单元格合并，最后将最终结果transform成txt文件。\n",
    "\n",
    "## 其他调参\n",
    "\n",
    "我们对bp_cutoff等参数进行了调整，以得到预测效果最好的数值。\n",
    "\n",
    "## 思路架构图\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/07b23feab73544f3a8e10b3a86a47841910212f2da334dedb7e73bcf8f8552d6)\n",
    "\n",
    "\n",
    "\n",
    "[1] He S, Gao B, Sabnis R, et al. NUCLEIC TRANSFORMER: DEEP LEARNING ON NUCLEIC ACIDS WITH SELF-ATTENTION AND CONVOLUTIONS[J]. bioRxiv, 2021.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
